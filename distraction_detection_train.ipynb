{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "from math import cos, sin\n",
    "import onnxruntime\n",
    "import numba as nb\n",
    "import io\n",
    "import sys\n",
    "import numpy as np\n",
    "import torch\n",
    "import pandas as pd\n",
    "from typing import List, Literal\n",
    "import itertools\n",
    "import datetime\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim import Adam\n",
    "import torch.nn.functional as F\n",
    "import pandas as pd\n",
    "from typing import List, Literal\n",
    "import itertools\n",
    "import datetime\n",
    "import json\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import easyocr\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Используемые функции"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def determine_roles(tensor):\n",
    "    \"\"\"\n",
    "    Определяет роли на основе средних x-координат ключевых точек.\n",
    "\n",
    "    Parameters:\n",
    "    - tensor: PyTorch тензор размером (число точек * число людей, 3), содержащий x, y координаты и вероятности для каждой точки.\n",
    "\n",
    "    Returns:\n",
    "    - Список ролей в порядке соответствия переданным спискам точек.\n",
    "    \"\"\"\n",
    "    if tensor.shape[0] < 2:\n",
    "        return []\n",
    "\n",
    "    num_people = tensor.shape[0] // 17\n",
    "\n",
    "    if num_people == 1:\n",
    "        return ['driver']\n",
    "\n",
    "    else:\n",
    "        num_points = tensor.shape[0] // 2\n",
    "        person1_points = tensor[:num_points, :]\n",
    "        person2_points = tensor[num_points:, :]\n",
    "\n",
    "        avg_x_person1 = torch.mean(person1_points[:, 0])\n",
    "        avg_x_person2 = torch.mean(person2_points[:, 0])\n",
    "\n",
    "        if avg_x_person1 > avg_x_person2:\n",
    "            return ['driver', 'assistant']\n",
    "        else:\n",
    "            return ['assistant', 'driver']\n",
    "\n",
    "\n",
    "\n",
    "def determine_box_roles(boxes):\n",
    "    \"\"\"\n",
    "    Определяет роли на основе средних x-координат баундинг боксов.\n",
    "\n",
    "    Parameters:\n",
    "    - boxes: список баундинг боксов.\n",
    "\n",
    "    Returns:\n",
    "    - Список ролей ('driver' или 'assistant') в порядке соответствия переданным баундинг боксам.\n",
    "    \"\"\"\n",
    "    if len(boxes) == 1:\n",
    "        return ['driver']\n",
    "\n",
    "    else:\n",
    "        avg_xs = [(box[0] + box[2]) / 2 for box in boxes]\n",
    "        sorted_indices = sorted(range(len(avg_xs)), key=lambda k: avg_xs[k])\n",
    "        roles = ['assistant' if i == sorted_indices[0] else 'driver' for i in range(len(boxes))]\n",
    "        return roles\n",
    "    \n",
    "\n",
    "# Функция для заполнения недостающих данных\n",
    "def fill_missing(data, size, dim=0):\n",
    "    if not data:\n",
    "        return torch.zeros(size)\n",
    "    else:\n",
    "        return torch.tensor(data).cpu()\n",
    "    \n",
    "\n",
    "\n",
    "def get_lb_results(\n",
    "        filename: str, \n",
    "        model_output: List[int], \n",
    "        video_fps: float,\n",
    "        smoothing_type: Literal['max', 'mode'],\n",
    "        window: int = 5) -> dict:\n",
    "    \n",
    "    df = pd.DataFrame.from_dict({'model_output': model_output})\n",
    "    if smoothing_type == 'max':\n",
    "        df['smoothed'] = df['model_output'].rolling(window=window, min_periods=1).max().astype('int')\n",
    "        df['smoothed_rev'] = df['model_output'].iloc[::-1].rolling(window=window, min_periods=1).max().astype('int').iloc[::-1]\n",
    "        df['smoothed'] = df['smoothed'] * df['smoothed_rev']\n",
    "    elif smoothing_type == 'mode':\n",
    "        df['smoothed'] = df['model_output'].rolling(window=window, min_periods=1).mean()\n",
    "        df['smoothed'] = df['smoothed'].apply(lambda x: 1 if x >= 0.5 else 0)\n",
    "\n",
    "    smoothed_list = df['smoothed'].tolist()\n",
    "    intervals = [(x[0], len(list(x[1]))) for x in itertools.groupby(smoothed_list)]\n",
    "\n",
    "    min_frames = 3 * video_fps\n",
    "    starting_times = []\n",
    "    for idx, interval in enumerate(intervals):\n",
    "        if interval[0] == 1 and interval[1] >= min_frames:\n",
    "            starting_frame = 0\n",
    "            if idx == 0:\n",
    "                starting_times.append('00:00')\n",
    "            else:\n",
    "                for i in range(idx):\n",
    "                    starting_frame += intervals[i][1]\n",
    "                num_seconds = int(starting_frame / video_fps)\n",
    "                starting_time = str(datetime.timedelta(seconds=num_seconds))[-5:]\n",
    "                starting_times.append(starting_time)\n",
    "\n",
    "    return {\n",
    "        'filename': filename,\n",
    "        'cases_count': len(starting_times),\n",
    "        'timestamps': starting_times\n",
    "    }\n",
    "\n",
    "\n",
    "def add_entry_to_json(role, date, dist):\n",
    "    try:\n",
    "        with open(\"data.json\", \"r\", encoding=\"utf-8\") as file:\n",
    "            loaded_data = json.load(file)\n",
    "            data = loaded_data[\"data\"]\n",
    "    except (FileNotFoundError, json.JSONDecodeError):\n",
    "        data = []\n",
    "    new_entry = {\n",
    "        \"role\": role,\n",
    "        \"date\": date,\n",
    "        \"dist\": dist\n",
    "    }\n",
    "\n",
    "    data.append(new_entry)\n",
    "\n",
    "    with open(\"data.json\", \"w\", encoding=\"utf-8\") as file:\n",
    "        json.dump({\"data\": data}, file, ensure_ascii=False, indent=4)\n",
    "\n",
    "\n",
    "\n",
    "class Dist_est(nn.Module):\n",
    "    def __init__(self, input_size=25, hidden_size=350, num_classes=3, dropout_prob=0.2):\n",
    "        super(Dist_est, self).__init__()\n",
    "\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        self.dropout1 = nn.Dropout(p=dropout_prob)\n",
    "        \n",
    "        self.fc2 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.dropout2 = nn.Dropout(p=dropout_prob)\n",
    "    \n",
    "        self.fc3 = nn.Linear(hidden_size, num_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout1(x)\n",
    "   \n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.dropout2(x)\n",
    "  \n",
    "        x = self.fc3(x)\n",
    "        \n",
    "        return x\n",
    "    \n",
    "\n",
    "idx_tensor_yaw = [np.array(idx, dtype=np.float32) for idx in range(120)]\n",
    "idx_tensor = [np.array(idx, dtype=np.float32) for idx in range(66)]\n",
    "\n",
    "\n",
    "def softmax(x):\n",
    "    x -= np.max(x,axis=1, keepdims=True)\n",
    "    a = np.exp(x)\n",
    "    b = np.sum(np.exp(x), axis=1, keepdims=True)\n",
    "    return a/b\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def resize_and_pad(src, size, pad_color=0):\n",
    "    ()\n",
    "    img = src\n",
    "    h, w = img.shape[:2]\n",
    "    sh, sw = size\n",
    "    if h > sh or w > sw:\n",
    "        interp = cv2.INTER_AREA\n",
    "    else:\n",
    "        interp = cv2.INTER_CUBIC\n",
    "    aspect = w/h\n",
    "    if aspect > 1:\n",
    "        new_w = sw\n",
    "        new_h = np.round(new_w/aspect).astype(int)\n",
    "        pad_vert = (sh-new_h)/2\n",
    "        pad_top, pad_bot = \\\n",
    "            np.floor(pad_vert).astype(int), np.ceil(pad_vert).astype(int)\n",
    "        pad_left, pad_right = 0, 0\n",
    "    elif aspect < 1:\n",
    "        new_h = sh\n",
    "        new_w = np.round(new_h*aspect).astype(int)\n",
    "        pad_horz = (sw-new_w)/2\n",
    "        pad_left, pad_right = \\\n",
    "            np.floor(pad_horz).astype(int), np.ceil(pad_horz).astype(int)\n",
    "        pad_top, pad_bot = 0, 0\n",
    "    else:\n",
    "        new_h, new_w = sh, sw\n",
    "        pad_left, pad_right, pad_top, pad_bot = 0, 0, 0, 0\n",
    "    if len(img.shape) == 3 and not isinstance(pad_color, (list, tuple, np.ndarray)):\n",
    "        pad_color = [pad_color]*3\n",
    "    scaled_img = cv2.resize(\n",
    "        img,\n",
    "        (new_w, new_h),\n",
    "        interpolation=interp\n",
    "    )\n",
    "    scaled_img = cv2.copyMakeBorder(\n",
    "        scaled_img,\n",
    "        pad_top,\n",
    "        pad_bot,\n",
    "        pad_left,\n",
    "        pad_right,\n",
    "        borderType=cv2.BORDER_CONSTANT,\n",
    "        value=pad_color\n",
    "    )\n",
    "    return scaled_img\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def filter_keypoints(data):\n",
    "    \"\"\"\n",
    "    Фильтрует ключевые точки тензора, оставляя только интересующие нас.\n",
    "\n",
    "    Parameters:\n",
    "    - data: PyTorch тензор размером (число людей, число точек, 3).\n",
    "\n",
    "    Returns:\n",
    "    - Тензор с отфильтрованными ключевыми точками.\n",
    "    \"\"\"\n",
    "\n",
    "    # Индексы ключевых точек COCO, которые нам интересны\n",
    "    required_indices = [0, 3, 4, 5, 6, 7, 8, 9, 10]\n",
    "\n",
    "    # Создаем пустой список для сохранения отфильтрованных точек\n",
    "    filtered_data = []\n",
    "\n",
    "    for person_keypoints in data:\n",
    "        filtered_person_keypoints = person_keypoints[required_indices]\n",
    "        filtered_data.append(filtered_person_keypoints)\n",
    "\n",
    "    return torch.stack(filtered_data)\n",
    "\n",
    "\n",
    "@nb.njit('i8[:](f4[:,:],f4[:], f4, b1)', fastmath=True, cache=True)\n",
    "def nms_cpu(boxes, confs, nms_thresh, min_mode):\n",
    "    x1 = boxes[:, 0]\n",
    "    y1 = boxes[:, 1]\n",
    "    x2 = boxes[:, 2]\n",
    "    y2 = boxes[:, 3]\n",
    "    areas = (x2 - x1) * (y2 - y1)\n",
    "    order = confs.argsort()[::-1]\n",
    "    keep = []\n",
    "    while order.size > 0:\n",
    "        idx_self = order[0]\n",
    "        idx_other = order[1:]\n",
    "        keep.append(idx_self)\n",
    "        xx1 = np.maximum(x1[idx_self], x1[idx_other])\n",
    "        yy1 = np.maximum(y1[idx_self], y1[idx_other])\n",
    "        xx2 = np.minimum(x2[idx_self], x2[idx_other])\n",
    "        yy2 = np.minimum(y2[idx_self], y2[idx_other])\n",
    "        w = np.maximum(0.0, xx2 - xx1)\n",
    "        h = np.maximum(0.0, yy2 - yy1)\n",
    "        inter = w * h\n",
    "        if min_mode:\n",
    "            over = inter / np.minimum(areas[order[0]], areas[order[1:]])\n",
    "        else:\n",
    "            over = inter / (areas[order[0]] + areas[order[1:]] - inter)\n",
    "        inds = np.where(over <= nms_thresh)[0]\n",
    "        order = order[inds + 1]\n",
    "    return np.array(keep)\n",
    "\n",
    "\n",
    "def main(args):\n",
    "    yolov4_head_H = 480\n",
    "    yolov4_head_W = 640\n",
    "    whenet_H = 224\n",
    "    whenet_W = 224\n",
    "\n",
    "    # YOLOv4-Head\n",
    "    yolov4_model_name = 'yolov4_headdetection'\n",
    "    yolov4_head = onnxruntime.InferenceSession(\n",
    "        f'C:/Users/heroe/HeadPoseEstimation-WHENet-yolov4-onnx-openvino/saved_model_{whenet_H}x{whenet_W}/{yolov4_model_name}_{yolov4_head_H}x{yolov4_head_W}.onnx',\n",
    "        providers=[\n",
    "            'CUDAExecutionProvider',\n",
    "            'CPUExecutionProvider',\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    yolov4_head_input_name = yolov4_head.get_inputs()[0].name\n",
    "    yolov4_head_output_names = [output.name for output in yolov4_head.get_outputs()]\n",
    "    yolov4_head_output_shapes = [output.shape for output in yolov4_head.get_outputs()]\n",
    "    assert yolov4_head_output_shapes[0] == [1, 18900, 1, 4] # boxes[N, num, classes, boxes]\n",
    "    assert yolov4_head_output_shapes[1] == [1, 18900, 1]    # confs[N, num, classes]\n",
    "\n",
    "    # WHENet\n",
    "    whenet_input_name = None\n",
    "    whenet_output_names = None\n",
    "    whenet_output_shapes = None\n",
    "    mean = [0.485, 0.456, 0.406]\n",
    "    std = [0.229, 0.224, 0.225]\n",
    "    if args.whenet_mode == 'onnx':\n",
    "        whenet = onnxruntime.InferenceSession(\n",
    "            f'C:/Users/heroe/HeadPoseEstimation-WHENet-yolov4-onnx-openvino/saved_model_{whenet_H}x{whenet_W}/whenet_1x3x224x224_prepost.onnx',\n",
    "            providers=[\n",
    "                'CUDAExecutionProvider',\n",
    "                'CPUExecutionProvider',\n",
    "            ]\n",
    "        )\n",
    "        whenet_input_name = whenet.get_inputs()[0].name\n",
    "        whenet_output_names = [output.name for output in whenet.get_outputs()]\n",
    "\n",
    "    exec_net = None\n",
    "    input_name = None\n",
    "    if args.whenet_mode == 'openvino':\n",
    "        from openvino.inference_engine import IECore\n",
    "        model_path = f'saved_model_{whenet_H}x{whenet_W}/openvino/FP16/whenet_{whenet_H}x{whenet_W}.xml'\n",
    "        ie = IECore()\n",
    "        net = ie.read_network(model_path, os.path.splitext(model_path)[0] + \".bin\")\n",
    "        exec_net = ie.load_network(network=net, device_name='CPU', num_requests=2)\n",
    "        input_name = next(iter(net.input_info))\n",
    "\n",
    "    cap_width = int(args.height_width.split('x')[1])\n",
    "    cap_height = int(args.height_width.split('x')[0])\n",
    "\n",
    "    cap = args.frame\n",
    "\n",
    "    frame = cap\n",
    "\n",
    "    conf_thresh = 0.60\n",
    "    nms_thresh = 0.50\n",
    "\n",
    "    # Resize\n",
    "    resized_frame = resize_and_pad(\n",
    "        frame,\n",
    "        (yolov4_head_H, yolov4_head_W)\n",
    "    )\n",
    "    width = resized_frame.shape[1]\n",
    "    height = resized_frame.shape[0]\n",
    "\n",
    "    rgb = resized_frame[..., ::-1]\n",
    "\n",
    "    chw = rgb.transpose(2, 0, 1)\n",
    "    # нормализация [0, 1]\n",
    "    chw = np.asarray(chw / 255., dtype=np.float32)\n",
    "    # hwc --> nhwc\n",
    "    nchw = chw[np.newaxis, ...]\n",
    "\n",
    "    boxes, confs = yolov4_head.run(\n",
    "        output_names = yolov4_head_output_names,\n",
    "        input_feed = {yolov4_head_input_name: nchw}\n",
    "    )\n",
    "   \n",
    "    boxes = boxes[0][:, 0, :]\n",
    "\n",
    "    confs = confs[0][:, 0]\n",
    "\n",
    "    argwhere = confs > conf_thresh\n",
    "    boxes = boxes[argwhere, :]\n",
    "    confs = confs[argwhere]\n",
    "    # nms\n",
    "    heads = []\n",
    "    keep = nms_cpu(\n",
    "        boxes=boxes,\n",
    "        confs=confs,\n",
    "        nms_thresh=nms_thresh,\n",
    "        min_mode=False\n",
    "    )\n",
    "    if (keep.size > 0):\n",
    "        boxes = boxes[keep, :]\n",
    "        confs = confs[keep]\n",
    "        for k in range(boxes.shape[0]):\n",
    "            heads.append(\n",
    "                [\n",
    "                    int(boxes[k, 0] * width),\n",
    "                    int(boxes[k, 1] * height),\n",
    "                    int(boxes[k, 2] * width),\n",
    "                    int(boxes[k, 3] * height),\n",
    "                    confs[k],\n",
    "                ]\n",
    "            )\n",
    "\n",
    "    canvas = resized_frame.copy()\n",
    "    # ============================================================= WHENet\n",
    "    mm = []\n",
    "\n",
    "    croped_resized_frame = None\n",
    "    if len(heads) > 0:\n",
    "        for head in heads:\n",
    "            ll = []\n",
    "            x_min = head[0]\n",
    "            y_min = head[1]\n",
    "            x_max = head[2]\n",
    "            y_max = head[3]\n",
    "\n",
    "            y_min = max(0, y_min - abs(y_min - y_max) / 10)\n",
    "            y_max = min(resized_frame.shape[0], y_max + abs(y_min - y_max) / 10)\n",
    "            x_min = max(0, x_min - abs(x_min - x_max) / 5)\n",
    "            x_max = min(resized_frame.shape[1], x_max + abs(x_min - x_max) / 5)\n",
    "            x_max = min(x_max, resized_frame.shape[1])\n",
    "            croped_frame = resized_frame[int(y_min):int(y_max), int(x_min):int(x_max)]\n",
    "            croped_resized_frame = cv2.resize(croped_frame, (whenet_W, whenet_H))\n",
    "            rgb = croped_resized_frame[..., ::-1]\n",
    "            chw = rgb.transpose(2, 0, 1)\n",
    "            nchw = np.asarray(chw[np.newaxis, :, :, :], dtype=np.float32)\n",
    "\n",
    "            yaw = 0.0\n",
    "            pitch = 0.0\n",
    "            roll = 0.0\n",
    "            if args.whenet_mode == 'onnx':\n",
    "                outputs = whenet.run(\n",
    "                    output_names = whenet_output_names,\n",
    "                    input_feed = {whenet_input_name: nchw}\n",
    "                )\n",
    "                yaw = outputs[0][0][0]\n",
    "                roll = outputs[0][0][1]\n",
    "                pitch = outputs[0][0][2]\n",
    "            elif args.whenet_mode == 'openvino':\n",
    "      \n",
    "                rgb = ((rgb / 255.0) - mean) / std\n",
    "                output = exec_net.infer(inputs={input_name: nchw})\n",
    "                yaw = output['yaw_new/BiasAdd/Add']\n",
    "                roll = output['roll_new/BiasAdd/Add']\n",
    "                pitch = output['pitch_new/BiasAdd/Add']\n",
    "\n",
    "            yaw, pitch, roll = np.squeeze([yaw, pitch, roll])\n",
    "            ll.append(yaw)\n",
    "            ll.append(pitch)\n",
    "            ll.append(roll)\n",
    "            mm.append(ll)\n",
    "    return mm, boxes\n",
    "\n",
    "            \n",
    "class Args:\n",
    "    def __init__(self, frame):\n",
    "        self.frame = frame\n",
    "\n",
    "    whenet_mode = 'onnx'\n",
    "    height_width = '480x640'\n",
    "\n",
    "\n",
    "def true_positive_for_class(y_true, y_pred, target_class):\n",
    "    matrix = confusion_matrix(y_true, y_pred)\n",
    "    if matrix.shape[0] <= target_class or matrix.shape[1] <= target_class:\n",
    "        return 0\n",
    "    return matrix[target_class, target_class]\n",
    "\n",
    "\n",
    "def get_date_from_image(image, reader):\n",
    "    \"\"\" returns 'YYYY-MM-DD' \"\"\"\n",
    "    cut = image[:100, 1300:,:]\n",
    "    result = reader.readtext(cut)\n",
    "    one_string = '-'.join([res[1] for res in result]).replace('*', '')\n",
    "    date = one_string.replace(' ', '')[:10]\n",
    "    return date\n",
    "\n",
    "\n",
    "reader = easyocr.Reader(['en'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Основная часть"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video FPS: 12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 person, 23.0ms\n",
      "Speed: 2.0ms preprocess, 23.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 backpack, 1 laptop, 2 cell phones, 34.0ms\n",
      "Speed: 2.0ms preprocess, 34.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 20.0ms\n",
      "Speed: 1.0ms preprocess, 20.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 backpack, 2 cell phones, 31.0ms\n",
      "Speed: 2.0ms preprocess, 31.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 36.0ms\n",
      "Speed: 2.0ms preprocess, 36.0ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 backpack, 1 cell phone, 1 book, 59.1ms\n",
      "Speed: 2.0ms preprocess, 59.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 27.0ms\n",
      "Speed: 2.0ms preprocess, 27.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 car, 1 backpack, 1 cell phone, 44.0ms\n",
      "Speed: 2.0ms preprocess, 44.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 117.1ms\n",
      "Speed: 2.0ms preprocess, 117.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 backpack, 1 cell phone, 31.0ms\n",
      "Speed: 2.0ms preprocess, 31.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 20.0ms\n",
      "Speed: 1.0ms preprocess, 20.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 backpack, 1 cell phone, 31.0ms\n",
      "Speed: 2.0ms preprocess, 31.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 35.0ms\n",
      "Speed: 1.0ms preprocess, 35.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 backpack, 1 cell phone, 58.1ms\n",
      "Speed: 2.0ms preprocess, 58.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 23.0ms\n",
      "Speed: 2.0ms preprocess, 23.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 backpack, 1 cell phone, 39.0ms\n",
      "Speed: 2.0ms preprocess, 39.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 54.0ms\n",
      "Speed: 1.0ms preprocess, 54.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 2 backpacks, 1 cell phone, 81.1ms\n",
      "Speed: 1.0ms preprocess, 81.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 21.0ms\n",
      "Speed: 1.0ms preprocess, 21.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 2 backpacks, 1 laptop, 2 cell phones, 32.0ms\n",
      "Speed: 2.0ms preprocess, 32.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 40.0ms\n",
      "Speed: 2.0ms preprocess, 40.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 2 backpacks, 1 handbag, 1 laptop, 2 cell phones, 63.1ms\n",
      "Speed: 2.0ms preprocess, 63.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 35.0ms\n",
      "Speed: 1.0ms preprocess, 35.0ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 2 backpacks, 1 bottle, 1 laptop, 2 cell phones, 56.1ms\n",
      "Speed: 2.0ms preprocess, 56.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 30.0ms\n",
      "Speed: 1.0ms preprocess, 30.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 2 backpacks, 1 laptop, 2 cell phones, 48.0ms\n",
      "Speed: 2.0ms preprocess, 48.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 30.0ms\n",
      "Speed: 2.0ms preprocess, 30.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 2 backpacks, 1 laptop, 2 cell phones, 46.0ms\n",
      "Speed: 2.0ms preprocess, 46.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 129.1ms\n",
      "Speed: 3.0ms preprocess, 129.1ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 2 backpacks, 1 laptop, 2 cell phones, 1 book, 108.1ms\n",
      "Speed: 2.0ms preprocess, 108.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    }
   ],
   "source": [
    "model_key_points = YOLO('yolov8l-pose.pt')\n",
    "model_key_cell_phone = YOLO('yolov8x.pt')\n",
    "\n",
    "model_main = Dist_est()\n",
    "\n",
    "model_path = r\"C:\\Users\\heroe\\Desktop\\dist_model_1.pth\"\n",
    "model_main.load_state_dict(torch.load(model_path))\n",
    "model_main.eval()\n",
    "\n",
    "video_path = r'F:\\train_train\\train_dataset_Бригады\\Анализ бригад (телефон)\\Есть телефон\\03_01_03.mp4'\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "# Проверяем, удалось ли открыть видео\n",
    "if not cap.isOpened():\n",
    "    print(\"Error.\")\n",
    "    exit()\n",
    "\n",
    "fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "print(f\"Video FPS: {fps}\")\n",
    "fr = 0\n",
    "\n",
    "ones_mech = []\n",
    "twos_mech = []\n",
    "threes_mech = []\n",
    "empty_mech = []\n",
    "\n",
    "ones_assest = []\n",
    "twos_assest = []\n",
    "threes_assest = []\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    fr+=1\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    if fr < 10:\n",
    "        data_stamp = get_date_from_image(frame, reader)\n",
    "\n",
    "    key_points = model_key_points(frame, show=False, conf = 0.35)\n",
    "\n",
    "    cell_phone = model_key_cell_phone(frame, show=False, conf = 0.2)\n",
    "    \n",
    "    cls = cell_phone[0].boxes.cls.cpu().numpy()\n",
    "    xyxyn = cell_phone[0].boxes.xyxyn.cpu().numpy()\n",
    "   \n",
    "    # Отфильтровываем только те боксы, которые относятся к cell_phone\n",
    "    cell_phone_boxes = xyxyn[cls == 67]\n",
    "\n",
    "    args = Args(frame)\n",
    "\n",
    "    cos_sin, boxi = main(args)\n",
    "\n",
    "    train_driver = []\n",
    "    helper = []\n",
    "    if key_points[0].keypoints.data.numel() == 0:\n",
    "        print('ПУСТОЙ ТЕНЗОР')\n",
    "        ones_mech.append(0)\n",
    "        twos_mech.append(0)\n",
    "        threes_mech.append(0)\n",
    "        empty_mech.append(1)\n",
    "        continue\n",
    "\n",
    "    #Роль для точек\n",
    "    roles_points = determine_roles(key_points[0].keypoints.data)\n",
    "    roles_box = determine_box_roles(boxi)\n",
    "    roles_box_cell = determine_box_roles(cell_phone_boxes)\n",
    "\n",
    "    #Только нужные ключевые точки\n",
    "    key_points_data = key_points[0].keypoints.data\n",
    "    filtered_data = filter_keypoints(key_points_data)\n",
    "\n",
    "    # Если в кадре только один человек\n",
    "    if len(roles_points) == 1:\n",
    "        role = roles_points[0]  \n",
    "        index_box = roles_box.index(role) if role in roles_box else None\n",
    "        index_points = 0  # так как у нас только одна роль в кадре\n",
    "        index_phone = roles_box_cell.index(role) if role in roles_box_cell else None\n",
    "        \n",
    "        cos_sin_data = fill_missing(cos_sin[index_box] if index_box is not None else None, [3])\n",
    "        points_data = fill_missing(filtered_data[index_points, :, :2].tolist(), [17, 2])\n",
    "        phone_data = fill_missing(cell_phone_boxes[index_phone].tolist() if (index_phone is not None and len(cell_phone_boxes) > index_phone) else None, [4])\n",
    "        \n",
    "        combined_tensor = torch.cat([cos_sin_data.flatten(), points_data.flatten(), phone_data.flatten()])\n",
    "\n",
    "    else:\n",
    "        driver_index_box = roles_box.index('driver') if 'driver' in roles_box else None\n",
    "        assistant_index_box = roles_box.index('assistant') if 'assistant' in roles_box else None\n",
    "        \n",
    "        driver_index_points = 0 if 'driver' in roles_points else None\n",
    "        assistant_index_points = 1 if 'assistant' in roles_points else None\n",
    "        \n",
    "        driver_index_phone = roles_box_cell.index('driver') if 'driver' in roles_box_cell else None\n",
    "        assistant_index_phone = roles_box_cell.index('assistant') if 'assistant' in roles_box_cell else None\n",
    "\n",
    "        # Извлечение данных\n",
    "        driver_cos_sin = fill_missing(cos_sin[driver_index_box] if driver_index_box is not None else None, [3])\n",
    "        assistant_cos_sin = fill_missing(cos_sin[assistant_index_box] if assistant_index_box is not None else None, [3])\n",
    "        \n",
    "        driver_points = fill_missing(filtered_data[driver_index_points, :, :2].tolist() if (driver_index_points is not None and len(filtered_data) > driver_index_points) else None, [9, 2])\n",
    "        assistant_points = fill_missing(filtered_data[assistant_index_points, :, :2].tolist() if (assistant_index_points is not None and len(filtered_data) > assistant_index_points) else None, [9, 2])\n",
    "        \n",
    "        driver_phone = fill_missing(cell_phone_boxes[driver_index_phone].tolist() if (driver_index_phone is not None and len(cell_phone_boxes) > driver_index_phone) else None, [4])\n",
    "        assistant_phone = fill_missing(cell_phone_boxes[assistant_index_phone].tolist() if (assistant_index_phone is not None and len(cell_phone_boxes) > assistant_index_phone) else None, [4])\n",
    "\n",
    "        # Объединение данных в один тензор\n",
    "        driver_tensor = torch.cat([driver_cos_sin.flatten(), driver_points.flatten(), driver_phone.flatten()])\n",
    "        assistant_tensor = torch.cat([assistant_cos_sin.flatten(), assistant_points.flatten(), assistant_phone.flatten()])\n",
    "\n",
    "\n",
    "    with torch.no_grad():\n",
    "        output = model_main(driver_tensor)\n",
    "\n",
    "    predicted_class_driver = torch.argmax(output).item()\n",
    "\n",
    "\n",
    "    if predicted_class_driver == 0:\n",
    "        ones_mech.append(1)\n",
    "        twos_mech.append(0)\n",
    "        threes_mech.append(0)\n",
    "    elif predicted_class_driver == 1:\n",
    "        ones_mech.append(0)\n",
    "        twos_mech.append(1)\n",
    "        threes_mech.append(0)\n",
    "    elif predicted_class_driver == 2:\n",
    "        ones_mech.append(0)\n",
    "        twos_mech.append(0)\n",
    "        threes_mech.append(1)\n",
    "\n",
    "\n",
    "    with torch.no_grad():\n",
    "        output = model_main(assistant_tensor)\n",
    "\n",
    "    predicted_class_assest = torch.argmax(output).item()\n",
    "\n",
    "\n",
    "    if predicted_class_assest == 0:\n",
    "        ones_assest.append(1)\n",
    "        twos_assest.append(0)\n",
    "        threes_assest.append(0)\n",
    "    elif predicted_class_driver == 1:\n",
    "        ones_assest.append(0)\n",
    "        twos_assest.append(1)\n",
    "        threes_assest.append(0)\n",
    "    elif predicted_class_driver == 2:\n",
    "        ones_assest.append(0)\n",
    "        twos_assest.append(0)\n",
    "        threes_assest.append(1)\n",
    "\n",
    "    # Освобождаем память, связанную с текущим кадром\n",
    "    del frame\n",
    "\n",
    "# Закрываем видеофайл\n",
    "cap.release()\n",
    "\n",
    "\n",
    "driver_time_stamp_ones = get_lb_results('test', ones_mech, 12, 'max', 5)\n",
    "driver_time_stamp_twos = get_lb_results('test', twos_mech, 12, 'max', 5)\n",
    "driver_time_stamp_threes = get_lb_results('test', threes_mech, 12, 'max', 5)\n",
    "\n",
    "assest_time_stamp_ones = get_lb_results('test', ones_assest, 12, 'max', 5)\n",
    "assest_time_stamp_twos = get_lb_results('test', twos_assest, 12, 'max', 5)\n",
    "assest_time_stamp_threes = get_lb_results('test', threes_assest, 12, 'max', 5)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver_stamps = [driver_time_stamp_ones, driver_time_stamp_twos, driver_time_stamp_threes]\n",
    "asset_stamps = [assest_time_stamp_ones, assest_time_stamp_twos]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "disturbed_mech = {1:'distracted', 2:'phone', 3:'empty_place'}\n",
    "listy = []\n",
    "\n",
    "count = 1\n",
    "for i in driver_stamps:\n",
    "    print(i)\n",
    "\n",
    "    for x in range(len(i['timestamps'])):\n",
    "        v = {\n",
    "        \"time_start\": data_stamp,\n",
    "        \"video_time\": i['timestamps'][x],\n",
    "        \"type\": disturbed_mech[count]\n",
    "        }\n",
    "        listy.append(v)\n",
    "    count+=1\n",
    "\n",
    "add_entry_to_json(\"Машинист\", data_stamp, listy)\n",
    "\n",
    "\n",
    "\n",
    "disturbed_assetst = {1:'distracted', 2:'phone'}\n",
    "listy = []\n",
    "\n",
    "count = 1\n",
    "for i in asset_stamps:\n",
    "    print(i)\n",
    "\n",
    "    for x in range(len(i['timestamps'])):\n",
    "        v = {\n",
    "        \"time_start\": data_stamp,\n",
    "        \"video_time\": i['timestamps'][x],\n",
    "        \"type\": disturbed_assetst[count]\n",
    "        }\n",
    "        listy.append(v)\n",
    "    count+=1\n",
    "\n",
    "add_entry_to_json(\"Помощник машиниста\", data_stamp, listy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Обработка и обучение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model_key_points = YOLO('yolov8l-pose.pt')\n",
    "model_key_cell_phone = YOLO('yolov8x.pt')\n",
    "\n",
    "images_folder_path = r'F:\\dataset\\train'\n",
    "\n",
    "all_files = os.listdir(images_folder_path)\n",
    "\n",
    "image_files = [f for f in all_files if os.path.splitext(f)[1] == '.jpg']\n",
    "\n",
    "for image_file in image_files:\n",
    "    image_path = os.path.join(images_folder_path, image_file)\n",
    "\n",
    "    frame = cv2.imread(image_path)\n",
    "\n",
    "    key_points = model_key_points(frame, show=False, conf = 0.8)\n",
    "\n",
    "    cell_phone = model_key_cell_phone(frame, show=False, conf = 0.5)\n",
    "\n",
    "    cls = cell_phone[0].boxes.cls.cpu().numpy()\n",
    "    xyxyn = cell_phone[0].boxes.xyxyn.cpu().numpy()\n",
    "  \n",
    "    cell_phone_boxes = xyxyn[cls == 67]\n",
    "    print(cell_phone_boxes)\n",
    "    args = Args(frame)\n",
    "    cos_sin, boxi = main(args)\n",
    "\n",
    "    train_driver = []\n",
    "    helper = []\n",
    "\n",
    "    if key_points[0].keypoints.data.numel() == 0:\n",
    "        print('ПУСТОЙ ТЕНЗОР')\n",
    "        continue\n",
    "    roles_points = determine_roles(key_points[0].keypoints.data)\n",
    "    roles_box = determine_box_roles(boxi)\n",
    "\n",
    "    roles_box_cell = determine_box_roles(cell_phone_boxes)\n",
    "    key_points_data = key_points[0].keypoints.data\n",
    "    filtered_data = filter_keypoints(key_points_data)\n",
    "\n",
    "    fr+=1\n",
    "\n",
    "    if len(roles_points) == 1:\n",
    "        role = roles_points[0]  \n",
    "        index_box = roles_box.index(role) if role in roles_box else None\n",
    "        index_points = 0  \n",
    "        index_phone = roles_box_cell.index(role) if role in roles_box_cell else None\n",
    "        cos_sin_data = fill_missing(cos_sin[index_box] if index_box is not None else None, [3])\n",
    "        points_data = fill_missing(filtered_data[index_points, :, :2].tolist(), [17, 2])\n",
    "        phone_data = fill_missing(cell_phone_boxes[index_phone].tolist() if (index_phone is not None and len(cell_phone_boxes) > index_phone) else None, [4])\n",
    "        combined_tensor = torch.cat([cos_sin_data.flatten(), points_data.flatten(), phone_data.flatten()])\n",
    "        print(combined_tensor)\n",
    "\n",
    "    else:\n",
    "        driver_index_box = roles_box.index('driver') if 'driver' in roles_box else None\n",
    "        assistant_index_box = roles_box.index('assistant') if 'assistant' in roles_box else None\n",
    "        \n",
    "        driver_index_points = 0 if 'driver' in roles_points else None\n",
    "        assistant_index_points = 1 if 'assistant' in roles_points else None\n",
    "        \n",
    "        driver_index_phone = roles_box_cell.index('driver') if 'driver' in roles_box_cell else None\n",
    "        assistant_index_phone = roles_box_cell.index('assistant') if 'assistant' in roles_box_cell else None\n",
    "\n",
    "    \n",
    "        driver_cos_sin = fill_missing(cos_sin[driver_index_box] if driver_index_box is not None else None, [3])\n",
    "        assistant_cos_sin = fill_missing(cos_sin[assistant_index_box] if assistant_index_box is not None else None, [3])\n",
    "        \n",
    "        driver_points = fill_missing(filtered_data[driver_index_points, :, :2].tolist() if (driver_index_points is not None and len(filtered_data) > driver_index_points) else None, [9, 2])\n",
    "        assistant_points = fill_missing(filtered_data[assistant_index_points, :, :2].tolist() if (assistant_index_points is not None and len(filtered_data) > assistant_index_points) else None, [9, 2])\n",
    "        \n",
    "        driver_phone = fill_missing(cell_phone_boxes[driver_index_phone].tolist() if (driver_index_phone is not None and len(cell_phone_boxes) > driver_index_phone) else None, [4])\n",
    "        assistant_phone = fill_missing(cell_phone_boxes[assistant_index_phone].tolist() if (assistant_index_phone is not None and len(cell_phone_boxes) > assistant_index_phone) else None, [4])\n",
    "\n",
    "      \n",
    "        driver_tensor = torch.cat([driver_cos_sin.flatten(), driver_points.flatten(), driver_phone.flatten()])\n",
    "        assistant_tensor = torch.cat([assistant_cos_sin.flatten(), assistant_points.flatten(), assistant_phone.flatten()])\n",
    "\n",
    "        print(driver_tensor)\n",
    "        print(assistant_tensor)\n",
    "    \n",
    "        tensor_name = os.path.splitext(image_file)[0] + '.pth'\n",
    "        tensor_save_path = os.path.join(images_folder_path, tensor_name)\n",
    "        \n",
    "        tensor_dict = {\n",
    "            'driver': driver_tensor,\n",
    "            'assistant': assistant_tensor\n",
    "        }\n",
    "\n",
    "        torch.save(tensor_dict, tensor_save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, folder_path):\n",
    "        self.folder_path = folder_path\n",
    "        self.file_list = [f for f in os.listdir(folder_path) if f.endswith('.pth')]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.file_list)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        file_name = self.file_list[idx]\n",
    "        \n",
    "        # Извлечение информации из имени файла\n",
    "        label, role, _ = file_name.split('_')\n",
    "        label = int(label)  # Метка класса\n",
    "        \n",
    "        data = torch.load(os.path.join(self.folder_path, file_name))\n",
    "        \n",
    "        # Выбор нужного тензора на основе роли из имени файла\n",
    "        if role == \"1\":\n",
    "            tensor_data = data[\"driver\"]\n",
    "        elif role == \"2\":\n",
    "            tensor_data = data[\"assistant\"]\n",
    "        else:\n",
    "            raise ValueError(\"Unexpected role value in filename.\")\n",
    "        \n",
    "        # Возвращаем тензор и метку\n",
    "        return tensor_data, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150, Train Loss: 21.6115, Train Acc: 41.66%, True Positives for Class 3 (Train): 539, Val Loss: 6.0361, Val Acc: 52.33%, True Positives for Class 3 (Val): 54\n",
      "Epoch 2/150, Train Loss: 13.0638, Train Acc: 47.88%, True Positives for Class 3 (Train): 614, Val Loss: 10.8801, Val Acc: 59.88%, True Positives for Class 3 (Val): 46\n",
      "Epoch 3/150, Train Loss: 10.0800, Train Acc: 50.72%, True Positives for Class 3 (Train): 628, Val Loss: 8.8001, Val Acc: 53.49%, True Positives for Class 3 (Val): 0\n",
      "Epoch 4/150, Train Loss: 7.2774, Train Acc: 54.41%, True Positives for Class 3 (Train): 684, Val Loss: 3.3842, Val Acc: 63.37%, True Positives for Class 3 (Val): 11\n",
      "Epoch 5/150, Train Loss: 6.3199, Train Acc: 55.30%, True Positives for Class 3 (Train): 702, Val Loss: 2.6093, Val Acc: 66.86%, True Positives for Class 3 (Val): 38\n",
      "Epoch 6/150, Train Loss: 5.3007, Train Acc: 55.13%, True Positives for Class 3 (Train): 725, Val Loss: 2.9720, Val Acc: 61.34%, True Positives for Class 3 (Val): 61\n",
      "Epoch 7/150, Train Loss: 4.4306, Train Acc: 57.25%, True Positives for Class 3 (Train): 715, Val Loss: 1.5352, Val Acc: 63.95%, True Positives for Class 3 (Val): 33\n",
      "Epoch 8/150, Train Loss: 3.5154, Train Acc: 58.34%, True Positives for Class 3 (Train): 729, Val Loss: 1.1338, Val Acc: 72.09%, True Positives for Class 3 (Val): 59\n",
      "Epoch 9/150, Train Loss: 3.0288, Train Acc: 58.58%, True Positives for Class 3 (Train): 749, Val Loss: 0.9886, Val Acc: 70.06%, True Positives for Class 3 (Val): 97\n",
      "Epoch 10/150, Train Loss: 2.5615, Train Acc: 58.62%, True Positives for Class 3 (Train): 743, Val Loss: 1.1588, Val Acc: 56.10%, True Positives for Class 3 (Val): 17\n",
      "Epoch 11/150, Train Loss: 2.2836, Train Acc: 57.83%, True Positives for Class 3 (Train): 740, Val Loss: 0.8002, Val Acc: 70.35%, True Positives for Class 3 (Val): 55\n",
      "Epoch 12/150, Train Loss: 2.0953, Train Acc: 58.69%, True Positives for Class 3 (Train): 766, Val Loss: 0.7865, Val Acc: 68.02%, True Positives for Class 3 (Val): 52\n",
      "Epoch 13/150, Train Loss: 1.8090, Train Acc: 58.65%, True Positives for Class 3 (Train): 760, Val Loss: 0.9420, Val Acc: 53.78%, True Positives for Class 3 (Val): 20\n",
      "Epoch 14/150, Train Loss: 1.5896, Train Acc: 58.62%, True Positives for Class 3 (Train): 743, Val Loss: 0.8399, Val Acc: 63.37%, True Positives for Class 3 (Val): 61\n",
      "Epoch 15/150, Train Loss: 1.3815, Train Acc: 57.83%, True Positives for Class 3 (Train): 749, Val Loss: 0.8377, Val Acc: 64.83%, True Positives for Class 3 (Val): 20\n",
      "Epoch 16/150, Train Loss: 1.2225, Train Acc: 57.97%, True Positives for Class 3 (Train): 749, Val Loss: 0.8690, Val Acc: 60.17%, True Positives for Class 3 (Val): 41\n",
      "Epoch 17/150, Train Loss: 1.1738, Train Acc: 57.35%, True Positives for Class 3 (Train): 744, Val Loss: 0.8642, Val Acc: 65.41%, True Positives for Class 3 (Val): 62\n",
      "Epoch 18/150, Train Loss: 1.0980, Train Acc: 58.34%, True Positives for Class 3 (Train): 752, Val Loss: 0.8655, Val Acc: 63.95%, True Positives for Class 3 (Val): 21\n",
      "Epoch 19/150, Train Loss: 1.0746, Train Acc: 58.89%, True Positives for Class 3 (Train): 775, Val Loss: 0.8902, Val Acc: 59.59%, True Positives for Class 3 (Val): 48\n",
      "Epoch 20/150, Train Loss: 0.9833, Train Acc: 59.06%, True Positives for Class 3 (Train): 760, Val Loss: 0.8893, Val Acc: 65.99%, True Positives for Class 3 (Val): 50\n",
      "Epoch 21/150, Train Loss: 0.9339, Train Acc: 61.11%, True Positives for Class 3 (Train): 823, Val Loss: 0.8938, Val Acc: 68.31%, True Positives for Class 3 (Val): 21\n",
      "Epoch 22/150, Train Loss: 0.9493, Train Acc: 60.12%, True Positives for Class 3 (Train): 760, Val Loss: 0.8732, Val Acc: 66.57%, True Positives for Class 3 (Val): 50\n",
      "Epoch 23/150, Train Loss: 0.9443, Train Acc: 58.99%, True Positives for Class 3 (Train): 755, Val Loss: 0.8493, Val Acc: 64.53%, True Positives for Class 3 (Val): 49\n",
      "Epoch 24/150, Train Loss: 0.8975, Train Acc: 60.60%, True Positives for Class 3 (Train): 783, Val Loss: 0.8391, Val Acc: 64.83%, True Positives for Class 3 (Val): 52\n",
      "Epoch 25/150, Train Loss: 0.8591, Train Acc: 62.07%, True Positives for Class 3 (Train): 797, Val Loss: 0.8184, Val Acc: 65.41%, True Positives for Class 3 (Val): 20\n",
      "Epoch 26/150, Train Loss: 0.8823, Train Acc: 61.80%, True Positives for Class 3 (Train): 766, Val Loss: 0.8025, Val Acc: 65.41%, True Positives for Class 3 (Val): 43\n",
      "Epoch 27/150, Train Loss: 0.8716, Train Acc: 61.63%, True Positives for Class 3 (Train): 795, Val Loss: 0.8056, Val Acc: 64.83%, True Positives for Class 3 (Val): 21\n",
      "Epoch 28/150, Train Loss: 0.8631, Train Acc: 62.45%, True Positives for Class 3 (Train): 811, Val Loss: 0.7653, Val Acc: 72.38%, True Positives for Class 3 (Val): 58\n",
      "Epoch 29/150, Train Loss: 0.8464, Train Acc: 61.70%, True Positives for Class 3 (Train): 791, Val Loss: 0.7494, Val Acc: 70.93%, True Positives for Class 3 (Val): 21\n",
      "Epoch 30/150, Train Loss: 0.8281, Train Acc: 62.72%, True Positives for Class 3 (Train): 786, Val Loss: 0.7470, Val Acc: 69.48%, True Positives for Class 3 (Val): 14\n",
      "Epoch 31/150, Train Loss: 0.8336, Train Acc: 63.61%, True Positives for Class 3 (Train): 804, Val Loss: 0.7355, Val Acc: 72.09%, True Positives for Class 3 (Val): 28\n",
      "Epoch 32/150, Train Loss: 0.8162, Train Acc: 63.89%, True Positives for Class 3 (Train): 814, Val Loss: 0.7251, Val Acc: 70.35%, True Positives for Class 3 (Val): 29\n",
      "Epoch 33/150, Train Loss: 0.7755, Train Acc: 65.29%, True Positives for Class 3 (Train): 844, Val Loss: 0.7146, Val Acc: 72.67%, True Positives for Class 3 (Val): 30\n",
      "Epoch 34/150, Train Loss: 0.7843, Train Acc: 64.12%, True Positives for Class 3 (Train): 817, Val Loss: 0.7121, Val Acc: 71.51%, True Positives for Class 3 (Val): 28\n",
      "Epoch 35/150, Train Loss: 0.7703, Train Acc: 66.07%, True Positives for Class 3 (Train): 834, Val Loss: 0.6935, Val Acc: 74.13%, True Positives for Class 3 (Val): 60\n",
      "Epoch 36/150, Train Loss: 0.7843, Train Acc: 64.91%, True Positives for Class 3 (Train): 835, Val Loss: 0.7043, Val Acc: 73.26%, True Positives for Class 3 (Val): 30\n",
      "Epoch 37/150, Train Loss: 0.7666, Train Acc: 65.32%, True Positives for Class 3 (Train): 857, Val Loss: 0.6944, Val Acc: 72.97%, True Positives for Class 3 (Val): 32\n",
      "Epoch 38/150, Train Loss: 0.7567, Train Acc: 66.48%, True Positives for Class 3 (Train): 851, Val Loss: 0.6875, Val Acc: 73.26%, True Positives for Class 3 (Val): 53\n",
      "Epoch 39/150, Train Loss: 0.7583, Train Acc: 66.21%, True Positives for Class 3 (Train): 825, Val Loss: 0.6838, Val Acc: 70.64%, True Positives for Class 3 (Val): 28\n",
      "Epoch 40/150, Train Loss: 0.7598, Train Acc: 65.87%, True Positives for Class 3 (Train): 834, Val Loss: 0.6700, Val Acc: 74.13%, True Positives for Class 3 (Val): 60\n",
      "Epoch 41/150, Train Loss: 0.7528, Train Acc: 66.55%, True Positives for Class 3 (Train): 844, Val Loss: 0.6539, Val Acc: 75.00%, True Positives for Class 3 (Val): 28\n",
      "Epoch 42/150, Train Loss: 0.7279, Train Acc: 67.61%, True Positives for Class 3 (Train): 877, Val Loss: 0.6617, Val Acc: 73.84%, True Positives for Class 3 (Val): 29\n",
      "Epoch 43/150, Train Loss: 0.7164, Train Acc: 68.26%, True Positives for Class 3 (Train): 871, Val Loss: 0.6478, Val Acc: 74.13%, True Positives for Class 3 (Val): 52\n",
      "Epoch 44/150, Train Loss: 0.7196, Train Acc: 68.37%, True Positives for Class 3 (Train): 874, Val Loss: 0.6503, Val Acc: 72.38%, True Positives for Class 3 (Val): 24\n",
      "Epoch 45/150, Train Loss: 0.7081, Train Acc: 68.98%, True Positives for Class 3 (Train): 881, Val Loss: 0.6458, Val Acc: 74.42%, True Positives for Class 3 (Val): 30\n",
      "Epoch 46/150, Train Loss: 0.7253, Train Acc: 67.27%, True Positives for Class 3 (Train): 854, Val Loss: 0.6535, Val Acc: 72.97%, True Positives for Class 3 (Val): 26\n",
      "Epoch 47/150, Train Loss: 0.7078, Train Acc: 68.47%, True Positives for Class 3 (Train): 863, Val Loss: 0.6324, Val Acc: 76.16%, True Positives for Class 3 (Val): 30\n",
      "Epoch 48/150, Train Loss: 0.7107, Train Acc: 68.43%, True Positives for Class 3 (Train): 886, Val Loss: 0.6387, Val Acc: 74.13%, True Positives for Class 3 (Val): 52\n",
      "Epoch 49/150, Train Loss: 0.7049, Train Acc: 69.39%, True Positives for Class 3 (Train): 855, Val Loss: 0.6323, Val Acc: 75.29%, True Positives for Class 3 (Val): 55\n",
      "Epoch 50/150, Train Loss: 0.6792, Train Acc: 68.95%, True Positives for Class 3 (Train): 879, Val Loss: 0.6241, Val Acc: 75.87%, True Positives for Class 3 (Val): 56\n",
      "Epoch 51/150, Train Loss: 0.6834, Train Acc: 68.98%, True Positives for Class 3 (Train): 900, Val Loss: 0.6223, Val Acc: 72.97%, True Positives for Class 3 (Val): 27\n",
      "Epoch 52/150, Train Loss: 0.6956, Train Acc: 68.84%, True Positives for Class 3 (Train): 865, Val Loss: 0.6229, Val Acc: 73.84%, True Positives for Class 3 (Val): 30\n",
      "Epoch 53/150, Train Loss: 0.6930, Train Acc: 70.18%, True Positives for Class 3 (Train): 896, Val Loss: 0.6212, Val Acc: 71.80%, True Positives for Class 3 (Val): 52\n",
      "Epoch 54/150, Train Loss: 0.6799, Train Acc: 70.49%, True Positives for Class 3 (Train): 892, Val Loss: 0.6139, Val Acc: 75.58%, True Positives for Class 3 (Val): 52\n",
      "Epoch 55/150, Train Loss: 0.6705, Train Acc: 70.59%, True Positives for Class 3 (Train): 876, Val Loss: 0.6068, Val Acc: 75.29%, True Positives for Class 3 (Val): 29\n",
      "Epoch 56/150, Train Loss: 0.6587, Train Acc: 70.25%, True Positives for Class 3 (Train): 896, Val Loss: 0.6011, Val Acc: 75.58%, True Positives for Class 3 (Val): 52\n",
      "Epoch 57/150, Train Loss: 0.6814, Train Acc: 70.25%, True Positives for Class 3 (Train): 903, Val Loss: 0.6069, Val Acc: 74.13%, True Positives for Class 3 (Val): 25\n",
      "Epoch 58/150, Train Loss: 0.6663, Train Acc: 70.86%, True Positives for Class 3 (Train): 892, Val Loss: 0.5894, Val Acc: 75.29%, True Positives for Class 3 (Val): 49\n",
      "Epoch 59/150, Train Loss: 0.6637, Train Acc: 70.69%, True Positives for Class 3 (Train): 893, Val Loss: 0.5981, Val Acc: 75.29%, True Positives for Class 3 (Val): 55\n",
      "Epoch 60/150, Train Loss: 0.6510, Train Acc: 71.20%, True Positives for Class 3 (Train): 906, Val Loss: 0.5858, Val Acc: 77.03%, True Positives for Class 3 (Val): 84\n",
      "Epoch 61/150, Train Loss: 0.6437, Train Acc: 72.61%, True Positives for Class 3 (Train): 934, Val Loss: 0.5928, Val Acc: 75.29%, True Positives for Class 3 (Val): 79\n",
      "Epoch 62/150, Train Loss: 0.6529, Train Acc: 71.55%, True Positives for Class 3 (Train): 910, Val Loss: 0.5884, Val Acc: 78.20%, True Positives for Class 3 (Val): 32\n",
      "Epoch 63/150, Train Loss: 0.6408, Train Acc: 71.85%, True Positives for Class 3 (Train): 929, Val Loss: 0.5819, Val Acc: 76.16%, True Positives for Class 3 (Val): 28\n",
      "Epoch 64/150, Train Loss: 0.6494, Train Acc: 71.92%, True Positives for Class 3 (Train): 898, Val Loss: 0.5764, Val Acc: 78.20%, True Positives for Class 3 (Val): 30\n",
      "Epoch 65/150, Train Loss: 0.6303, Train Acc: 72.50%, True Positives for Class 3 (Train): 928, Val Loss: 0.5762, Val Acc: 77.33%, True Positives for Class 3 (Val): 84\n",
      "Epoch 66/150, Train Loss: 0.6391, Train Acc: 72.47%, True Positives for Class 3 (Train): 915, Val Loss: 0.5807, Val Acc: 78.20%, True Positives for Class 3 (Val): 58\n",
      "Epoch 67/150, Train Loss: 0.6362, Train Acc: 71.82%, True Positives for Class 3 (Train): 928, Val Loss: 0.5687, Val Acc: 77.33%, True Positives for Class 3 (Val): 53\n",
      "Epoch 68/150, Train Loss: 0.6269, Train Acc: 72.61%, True Positives for Class 3 (Train): 936, Val Loss: 0.5750, Val Acc: 76.74%, True Positives for Class 3 (Val): 49\n",
      "Epoch 69/150, Train Loss: 0.6206, Train Acc: 73.36%, True Positives for Class 3 (Train): 921, Val Loss: 0.5653, Val Acc: 75.29%, True Positives for Class 3 (Val): 53\n",
      "Epoch 70/150, Train Loss: 0.6255, Train Acc: 72.95%, True Positives for Class 3 (Train): 915, Val Loss: 0.5753, Val Acc: 76.16%, True Positives for Class 3 (Val): 52\n",
      "Epoch 71/150, Train Loss: 0.6140, Train Acc: 72.50%, True Positives for Class 3 (Train): 910, Val Loss: 0.5676, Val Acc: 79.07%, True Positives for Class 3 (Val): 57\n",
      "Epoch 72/150, Train Loss: 0.6182, Train Acc: 73.02%, True Positives for Class 3 (Train): 920, Val Loss: 0.5688, Val Acc: 77.33%, True Positives for Class 3 (Val): 55\n",
      "Epoch 73/150, Train Loss: 0.6076, Train Acc: 73.46%, True Positives for Class 3 (Train): 925, Val Loss: 0.5605, Val Acc: 77.33%, True Positives for Class 3 (Val): 57\n",
      "Epoch 74/150, Train Loss: 0.6114, Train Acc: 73.15%, True Positives for Class 3 (Train): 937, Val Loss: 0.5630, Val Acc: 75.87%, True Positives for Class 3 (Val): 29\n",
      "Epoch 75/150, Train Loss: 0.5952, Train Acc: 73.53%, True Positives for Class 3 (Train): 915, Val Loss: 0.5610, Val Acc: 75.29%, True Positives for Class 3 (Val): 28\n",
      "Epoch 76/150, Train Loss: 0.6016, Train Acc: 73.60%, True Positives for Class 3 (Train): 916, Val Loss: 0.5574, Val Acc: 77.03%, True Positives for Class 3 (Val): 51\n",
      "Epoch 77/150, Train Loss: 0.6086, Train Acc: 73.26%, True Positives for Class 3 (Train): 920, Val Loss: 0.5519, Val Acc: 77.91%, True Positives for Class 3 (Val): 53\n",
      "Epoch 78/150, Train Loss: 0.6000, Train Acc: 73.77%, True Positives for Class 3 (Train): 949, Val Loss: 0.5517, Val Acc: 76.16%, True Positives for Class 3 (Val): 73\n",
      "Epoch 79/150, Train Loss: 0.6023, Train Acc: 73.97%, True Positives for Class 3 (Train): 929, Val Loss: 0.5438, Val Acc: 78.20%, True Positives for Class 3 (Val): 56\n",
      "Epoch 80/150, Train Loss: 0.5898, Train Acc: 74.15%, True Positives for Class 3 (Train): 942, Val Loss: 0.5475, Val Acc: 78.20%, True Positives for Class 3 (Val): 80\n",
      "Epoch 81/150, Train Loss: 0.5883, Train Acc: 75.10%, True Positives for Class 3 (Train): 937, Val Loss: 0.5369, Val Acc: 77.62%, True Positives for Class 3 (Val): 83\n",
      "Epoch 82/150, Train Loss: 0.5815, Train Acc: 74.76%, True Positives for Class 3 (Train): 950, Val Loss: 0.5373, Val Acc: 79.65%, True Positives for Class 3 (Val): 57\n",
      "Epoch 83/150, Train Loss: 0.5897, Train Acc: 74.49%, True Positives for Class 3 (Train): 958, Val Loss: 0.5426, Val Acc: 77.33%, True Positives for Class 3 (Val): 81\n",
      "Epoch 84/150, Train Loss: 0.5738, Train Acc: 75.75%, True Positives for Class 3 (Train): 945, Val Loss: 0.5296, Val Acc: 79.36%, True Positives for Class 3 (Val): 55\n",
      "Epoch 85/150, Train Loss: 0.5778, Train Acc: 74.56%, True Positives for Class 3 (Train): 938, Val Loss: 0.5365, Val Acc: 79.65%, True Positives for Class 3 (Val): 82\n",
      "Epoch 86/150, Train Loss: 0.5822, Train Acc: 74.86%, True Positives for Class 3 (Train): 925, Val Loss: 0.5288, Val Acc: 78.20%, True Positives for Class 3 (Val): 29\n",
      "Epoch 87/150, Train Loss: 0.5654, Train Acc: 75.51%, True Positives for Class 3 (Train): 945, Val Loss: 0.5324, Val Acc: 79.36%, True Positives for Class 3 (Val): 80\n",
      "Epoch 88/150, Train Loss: 0.5645, Train Acc: 76.03%, True Positives for Class 3 (Train): 932, Val Loss: 0.5308, Val Acc: 78.20%, True Positives for Class 3 (Val): 80\n",
      "Epoch 89/150, Train Loss: 0.5708, Train Acc: 75.31%, True Positives for Class 3 (Train): 937, Val Loss: 0.5338, Val Acc: 76.74%, True Positives for Class 3 (Val): 79\n",
      "Epoch 90/150, Train Loss: 0.5787, Train Acc: 75.31%, True Positives for Class 3 (Train): 944, Val Loss: 0.5192, Val Acc: 78.49%, True Positives for Class 3 (Val): 78\n",
      "Epoch 91/150, Train Loss: 0.5671, Train Acc: 75.14%, True Positives for Class 3 (Train): 939, Val Loss: 0.5353, Val Acc: 77.62%, True Positives for Class 3 (Val): 83\n",
      "Epoch 92/150, Train Loss: 0.5490, Train Acc: 76.54%, True Positives for Class 3 (Train): 941, Val Loss: 0.5158, Val Acc: 79.07%, True Positives for Class 3 (Val): 84\n",
      "Epoch 93/150, Train Loss: 0.5569, Train Acc: 75.79%, True Positives for Class 3 (Train): 942, Val Loss: 0.5333, Val Acc: 77.91%, True Positives for Class 3 (Val): 80\n",
      "Epoch 94/150, Train Loss: 0.5520, Train Acc: 76.27%, True Positives for Class 3 (Train): 949, Val Loss: 0.5121, Val Acc: 79.36%, True Positives for Class 3 (Val): 80\n",
      "Epoch 95/150, Train Loss: 0.5510, Train Acc: 75.82%, True Positives for Class 3 (Train): 941, Val Loss: 0.5192, Val Acc: 78.78%, True Positives for Class 3 (Val): 31\n",
      "Epoch 96/150, Train Loss: 0.5461, Train Acc: 76.71%, True Positives for Class 3 (Train): 966, Val Loss: 0.5123, Val Acc: 78.78%, True Positives for Class 3 (Val): 55\n",
      "Epoch 97/150, Train Loss: 0.5438, Train Acc: 76.78%, True Positives for Class 3 (Train): 953, Val Loss: 0.5042, Val Acc: 81.10%, True Positives for Class 3 (Val): 87\n",
      "Epoch 98/150, Train Loss: 0.5456, Train Acc: 76.47%, True Positives for Class 3 (Train): 946, Val Loss: 0.5042, Val Acc: 81.40%, True Positives for Class 3 (Val): 57\n",
      "Epoch 99/150, Train Loss: 0.5493, Train Acc: 76.09%, True Positives for Class 3 (Train): 948, Val Loss: 0.5119, Val Acc: 79.94%, True Positives for Class 3 (Val): 81\n",
      "Epoch 100/150, Train Loss: 0.5447, Train Acc: 76.16%, True Positives for Class 3 (Train): 940, Val Loss: 0.5155, Val Acc: 79.65%, True Positives for Class 3 (Val): 87\n",
      "Epoch 101/150, Train Loss: 0.5429, Train Acc: 76.98%, True Positives for Class 3 (Train): 948, Val Loss: 0.5076, Val Acc: 81.40%, True Positives for Class 3 (Val): 87\n",
      "Epoch 102/150, Train Loss: 0.5314, Train Acc: 77.12%, True Positives for Class 3 (Train): 961, Val Loss: 0.4958, Val Acc: 79.94%, True Positives for Class 3 (Val): 81\n",
      "Epoch 103/150, Train Loss: 0.5333, Train Acc: 77.19%, True Positives for Class 3 (Train): 966, Val Loss: 0.4994, Val Acc: 80.81%, True Positives for Class 3 (Val): 85\n",
      "Epoch 104/150, Train Loss: 0.5286, Train Acc: 77.74%, True Positives for Class 3 (Train): 961, Val Loss: 0.5026, Val Acc: 80.81%, True Positives for Class 3 (Val): 88\n",
      "Epoch 105/150, Train Loss: 0.5353, Train Acc: 77.26%, True Positives for Class 3 (Train): 957, Val Loss: 0.4854, Val Acc: 81.69%, True Positives for Class 3 (Val): 88\n",
      "Epoch 106/150, Train Loss: 0.5299, Train Acc: 78.01%, True Positives for Class 3 (Train): 966, Val Loss: 0.4907, Val Acc: 79.65%, True Positives for Class 3 (Val): 83\n",
      "Epoch 107/150, Train Loss: 0.5316, Train Acc: 77.63%, True Positives for Class 3 (Train): 968, Val Loss: 0.5117, Val Acc: 79.65%, True Positives for Class 3 (Val): 111\n",
      "Epoch 108/150, Train Loss: 0.5182, Train Acc: 77.70%, True Positives for Class 3 (Train): 954, Val Loss: 0.4945, Val Acc: 79.07%, True Positives for Class 3 (Val): 118\n",
      "Epoch 109/150, Train Loss: 0.5140, Train Acc: 77.84%, True Positives for Class 3 (Train): 962, Val Loss: 0.4944, Val Acc: 79.94%, True Positives for Class 3 (Val): 112\n",
      "Epoch 110/150, Train Loss: 0.5152, Train Acc: 78.15%, True Positives for Class 3 (Train): 979, Val Loss: 0.4827, Val Acc: 81.40%, True Positives for Class 3 (Val): 56\n",
      "Epoch 111/150, Train Loss: 0.5056, Train Acc: 77.77%, True Positives for Class 3 (Train): 958, Val Loss: 0.4889, Val Acc: 82.27%, True Positives for Class 3 (Val): 87\n",
      "Epoch 112/150, Train Loss: 0.5124, Train Acc: 78.56%, True Positives for Class 3 (Train): 966, Val Loss: 0.4877, Val Acc: 81.98%, True Positives for Class 3 (Val): 88\n",
      "Epoch 113/150, Train Loss: 0.5061, Train Acc: 78.97%, True Positives for Class 3 (Train): 976, Val Loss: 0.4821, Val Acc: 81.40%, True Positives for Class 3 (Val): 58\n",
      "Epoch 114/150, Train Loss: 0.5138, Train Acc: 78.45%, True Positives for Class 3 (Train): 979, Val Loss: 0.4855, Val Acc: 81.40%, True Positives for Class 3 (Val): 87\n",
      "Epoch 115/150, Train Loss: 0.5018, Train Acc: 78.69%, True Positives for Class 3 (Train): 964, Val Loss: 0.4742, Val Acc: 82.27%, True Positives for Class 3 (Val): 88\n",
      "Epoch 116/150, Train Loss: 0.5140, Train Acc: 78.21%, True Positives for Class 3 (Train): 976, Val Loss: 0.4734, Val Acc: 82.27%, True Positives for Class 3 (Val): 59\n",
      "Epoch 117/150, Train Loss: 0.5149, Train Acc: 77.84%, True Positives for Class 3 (Train): 967, Val Loss: 0.4802, Val Acc: 80.81%, True Positives for Class 3 (Val): 89\n",
      "Epoch 118/150, Train Loss: 0.5023, Train Acc: 78.56%, True Positives for Class 3 (Train): 965, Val Loss: 0.4737, Val Acc: 81.98%, True Positives for Class 3 (Val): 88\n",
      "Epoch 119/150, Train Loss: 0.4854, Train Acc: 79.24%, True Positives for Class 3 (Train): 979, Val Loss: 0.4734, Val Acc: 80.81%, True Positives for Class 3 (Val): 58\n",
      "Epoch 120/150, Train Loss: 0.5120, Train Acc: 78.18%, True Positives for Class 3 (Train): 971, Val Loss: 0.4794, Val Acc: 80.81%, True Positives for Class 3 (Val): 58\n",
      "Epoch 121/150, Train Loss: 0.4957, Train Acc: 78.83%, True Positives for Class 3 (Train): 972, Val Loss: 0.4798, Val Acc: 82.27%, True Positives for Class 3 (Val): 118\n",
      "Epoch 122/150, Train Loss: 0.4894, Train Acc: 79.75%, True Positives for Class 3 (Train): 990, Val Loss: 0.4713, Val Acc: 83.43%, True Positives for Class 3 (Val): 90\n",
      "Epoch 123/150, Train Loss: 0.4831, Train Acc: 79.24%, True Positives for Class 3 (Train): 991, Val Loss: 0.4620, Val Acc: 82.27%, True Positives for Class 3 (Val): 120\n",
      "Epoch 124/150, Train Loss: 0.4868, Train Acc: 79.27%, True Positives for Class 3 (Train): 989, Val Loss: 0.4726, Val Acc: 82.85%, True Positives for Class 3 (Val): 60\n",
      "Epoch 125/150, Train Loss: 0.4774, Train Acc: 79.96%, True Positives for Class 3 (Train): 982, Val Loss: 0.4745, Val Acc: 81.98%, True Positives for Class 3 (Val): 116\n",
      "Epoch 126/150, Train Loss: 0.4770, Train Acc: 79.45%, True Positives for Class 3 (Train): 983, Val Loss: 0.4743, Val Acc: 82.27%, True Positives for Class 3 (Val): 89\n",
      "Epoch 127/150, Train Loss: 0.4948, Train Acc: 79.10%, True Positives for Class 3 (Train): 983, Val Loss: 0.4787, Val Acc: 80.81%, True Positives for Class 3 (Val): 84\n",
      "Epoch 128/150, Train Loss: 0.4917, Train Acc: 79.55%, True Positives for Class 3 (Train): 978, Val Loss: 0.4672, Val Acc: 83.14%, True Positives for Class 3 (Val): 92\n",
      "Epoch 129/150, Train Loss: 0.4827, Train Acc: 80.03%, True Positives for Class 3 (Train): 992, Val Loss: 0.4566, Val Acc: 82.56%, True Positives for Class 3 (Val): 120\n",
      "Epoch 130/150, Train Loss: 0.4687, Train Acc: 79.69%, True Positives for Class 3 (Train): 994, Val Loss: 0.4625, Val Acc: 81.98%, True Positives for Class 3 (Val): 89\n",
      "Epoch 131/150, Train Loss: 0.4753, Train Acc: 79.48%, True Positives for Class 3 (Train): 951, Val Loss: 0.4568, Val Acc: 83.14%, True Positives for Class 3 (Val): 32\n",
      "Epoch 132/150, Train Loss: 0.4814, Train Acc: 80.13%, True Positives for Class 3 (Train): 1003, Val Loss: 0.4698, Val Acc: 82.27%, True Positives for Class 3 (Val): 60\n",
      "Epoch 133/150, Train Loss: 0.4705, Train Acc: 79.99%, True Positives for Class 3 (Train): 977, Val Loss: 0.4728, Val Acc: 82.56%, True Positives for Class 3 (Val): 32\n",
      "Epoch 134/150, Train Loss: 0.4749, Train Acc: 80.20%, True Positives for Class 3 (Train): 1004, Val Loss: 0.4611, Val Acc: 81.69%, True Positives for Class 3 (Val): 119\n",
      "Epoch 135/150, Train Loss: 0.4624, Train Acc: 80.57%, True Positives for Class 3 (Train): 992, Val Loss: 0.4602, Val Acc: 84.30%, True Positives for Class 3 (Val): 119\n",
      "Epoch 136/150, Train Loss: 0.4672, Train Acc: 80.51%, True Positives for Class 3 (Train): 994, Val Loss: 0.4557, Val Acc: 83.14%, True Positives for Class 3 (Val): 118\n",
      "Epoch 137/150, Train Loss: 0.4611, Train Acc: 79.89%, True Positives for Class 3 (Train): 978, Val Loss: 0.4630, Val Acc: 82.85%, True Positives for Class 3 (Val): 61\n",
      "Epoch 138/150, Train Loss: 0.4763, Train Acc: 79.58%, True Positives for Class 3 (Train): 980, Val Loss: 0.4723, Val Acc: 83.72%, True Positives for Class 3 (Val): 62\n",
      "Epoch 139/150, Train Loss: 0.4612, Train Acc: 80.40%, True Positives for Class 3 (Train): 1011, Val Loss: 0.4655, Val Acc: 81.40%, True Positives for Class 3 (Val): 57\n",
      "Epoch 140/150, Train Loss: 0.4565, Train Acc: 79.99%, True Positives for Class 3 (Train): 979, Val Loss: 0.4534, Val Acc: 82.27%, True Positives for Class 3 (Val): 86\n",
      "Epoch 141/150, Train Loss: 0.4693, Train Acc: 80.27%, True Positives for Class 3 (Train): 983, Val Loss: 0.4630, Val Acc: 83.14%, True Positives for Class 3 (Val): 61\n",
      "Epoch 142/150, Train Loss: 0.4550, Train Acc: 80.51%, True Positives for Class 3 (Train): 1001, Val Loss: 0.4682, Val Acc: 82.85%, True Positives for Class 3 (Val): 86\n",
      "Epoch 143/150, Train Loss: 0.4557, Train Acc: 80.61%, True Positives for Class 3 (Train): 980, Val Loss: 0.4571, Val Acc: 82.56%, True Positives for Class 3 (Val): 91\n",
      "Epoch 144/150, Train Loss: 0.4520, Train Acc: 81.16%, True Positives for Class 3 (Train): 1010, Val Loss: 0.4551, Val Acc: 83.43%, True Positives for Class 3 (Val): 119\n",
      "Epoch 145/150, Train Loss: 0.4474, Train Acc: 81.26%, True Positives for Class 3 (Train): 1001, Val Loss: 0.4707, Val Acc: 81.69%, True Positives for Class 3 (Val): 56\n",
      "Epoch 146/150, Train Loss: 0.4438, Train Acc: 80.75%, True Positives for Class 3 (Train): 993, Val Loss: 0.4579, Val Acc: 81.69%, True Positives for Class 3 (Val): 87\n",
      "Epoch 147/150, Train Loss: 0.4511, Train Acc: 81.81%, True Positives for Class 3 (Train): 997, Val Loss: 0.4693, Val Acc: 81.69%, True Positives for Class 3 (Val): 90\n",
      "Epoch 148/150, Train Loss: 0.4457, Train Acc: 81.50%, True Positives for Class 3 (Train): 1006, Val Loss: 0.4756, Val Acc: 81.40%, True Positives for Class 3 (Val): 56\n",
      "Epoch 149/150, Train Loss: 0.4445, Train Acc: 80.71%, True Positives for Class 3 (Train): 981, Val Loss: 0.4502, Val Acc: 82.27%, True Positives for Class 3 (Val): 60\n",
      "Epoch 150/150, Train Loss: 0.4377, Train Acc: 82.01%, True Positives for Class 3 (Train): 1004, Val Loss: 0.4719, Val Acc: 83.14%, True Positives for Class 3 (Val): 61\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim import Adam\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Dist_est(nn.Module):\n",
    "    def __init__(self, input_size=25, hidden_size=350, num_classes=3, dropout_prob=0.2):\n",
    "        super(Dist_est, self).__init__()\n",
    "        \n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        self.dropout1 = nn.Dropout(p=dropout_prob)  \n",
    "        \n",
    "        self.fc2 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.dropout2 = nn.Dropout(p=dropout_prob) \n",
    "        \n",
    "        self.fc3 = nn.Linear(hidden_size, num_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout1(x) \n",
    "        \n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.dropout2(x)\n",
    "        \n",
    "        x = self.fc3(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "\n",
    "# Создание экземпляра модели, функции потерь и оптимизатора\n",
    "model = Dist_est()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = Adam(model.parameters(), lr=0.0001)\n",
    "\n",
    "# Создание DataLoader\n",
    "train_dataset = CustomDataset(folder_path=r\"F:\\dataset\\train_pth\")\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=0)\n",
    "\n",
    "val_dataset = CustomDataset(folder_path=r\"F:\\dataset\\val_pth\")\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=32, shuffle=False, num_workers=0)\n",
    "\n",
    "\n",
    "# Главный цикл\n",
    "num_epochs = 150  \n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    \n",
    "    # Тренировка\n",
    "    train_loss = 0.0\n",
    "    correct_train = 0\n",
    "    total_train = 0\n",
    "    true_positive_train_class_3 = 0 \n",
    "    \n",
    "    for batch_data, batch_labels in train_dataloader:\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        outputs = model(batch_data)\n",
    "        loss = criterion(outputs, batch_labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        train_loss += loss.item()\n",
    "        _, predicted = outputs.max(1)\n",
    "        total_train += batch_labels.size(0)\n",
    "        correct_train += predicted.eq(batch_labels).sum().item()\n",
    "        \n",
    "        true_positive_train_class_3 += true_positive_for_class(batch_labels.cpu().numpy(), predicted.cpu().numpy(), 2)\n",
    "    \n",
    "    train_accuracy = 100 * correct_train / total_train\n",
    "    \n",
    "    # Валидация\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    correct_val = 0\n",
    "    total_val = 0\n",
    "    true_positive_val_class_3 = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch_data, batch_labels in val_dataloader:\n",
    "            outputs = model(batch_data)\n",
    "            loss = criterion(outputs, batch_labels)\n",
    "            \n",
    "            val_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            total_val += batch_labels.size(0)\n",
    "            correct_val += predicted.eq(batch_labels).sum().item()\n",
    "            \n",
    "            true_positive_val_class_3 += true_positive_for_class(batch_labels.cpu().numpy(), predicted.cpu().numpy(), 2)\n",
    "    \n",
    "    val_accuracy = 100 * correct_val / total_val\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Train Loss: {train_loss/len(train_dataloader):.4f}, Train Acc: {train_accuracy:.2f}%, True Positives for Class 3 (Train): {true_positive_train_class_3}, Val Loss: {val_loss/len(val_dataloader):.4f}, Val Acc: {val_accuracy:.2f}%, True Positives for Class 3 (Val): {true_positive_val_class_3}\")\n",
    "\n",
    "torch.save(model.state_dict(), \"dist_model_1.pth\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python_311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
